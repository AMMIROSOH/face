{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9016ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit  # initializes CUDA driver\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38839d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "# 1. Load the engine\n",
    "with open(\"checkpoints/RetinaFace-R50.engine\", \"rb\") as f:\n",
    "    runtime = trt.Runtime(TRT_LOGGER)\n",
    "    engine = runtime.deserialize_cuda_engine(f.read())\n",
    "\n",
    "# 2. Create context\n",
    "context = engine.create_execution_context()\n",
    "\n",
    "# 3. Allocate buffers\n",
    "inputs, outputs, bindings, stream = [], [], [], cuda.Stream()\n",
    "\n",
    "for i in range(engine.num_io_tensors):\n",
    "    tensor_name = engine.get_tensor_name(i)\n",
    "    size = trt.volume(engine.get_tensor_shape(tensor_name))\n",
    "    dtype = trt.nptype(engine.get_tensor_dtype(tensor_name))\n",
    "\n",
    "    host_mem = cuda.pagelocked_empty(size, dtype)\n",
    "    device_mem = cuda.mem_alloc(host_mem.nbytes)\n",
    "\n",
    "    bindings.append(int(device_mem))\n",
    "    if engine.get_tensor_mode(tensor_name) == trt.TensorIOMode.INPUT:\n",
    "        inputs.append((host_mem, device_mem))\n",
    "    else:\n",
    "        outputs.append((host_mem, device_mem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4538af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(input_numpy):\n",
    "    # Copy input data to host buffer\n",
    "    np.copyto(inputs[0][0], input_numpy.ravel())\n",
    "\n",
    "    # Transfer to GPU\n",
    "    cuda.memcpy_htod_async(inputs[0][1], inputs[0][0], stream)\n",
    "\n",
    "    # Execute\n",
    "    context.execute_v2(bindings)\n",
    "\n",
    "    # Transfer outputs back\n",
    "    cuda.memcpy_dtoh_async(outputs[0][0], outputs[0][1], stream)\n",
    "    cuda.memcpy_dtoh_async(outputs[1][0], outputs[1][1], stream)\n",
    "    cuda.memcpy_dtoh_async(outputs[2][0], outputs[2][1], stream)\n",
    "    stream.synchronize()\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "818a9991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg inference time: 13.821144104003906 ms\n"
     ]
    }
   ],
   "source": [
    "def measure_inference_time(repetitions=100):\n",
    "    input_tensor = np.random.randn(repetitions, 3, 640, 640).astype(np.float32)\n",
    "\n",
    "    # warmup\n",
    "    for i in range(10):\n",
    "        _ = infer(input_tensor[i:i+1])\n",
    "\n",
    "    start = time.time()\n",
    "    for i in range(repetitions):\n",
    "        _ = infer(input_tensor[i:i+1])\n",
    "    end = time.time()\n",
    "\n",
    "    avg_time = (end - start) / repetitions\n",
    "    return avg_time\n",
    "\n",
    "print(\"Avg inference time:\", measure_inference_time() * 1000, \"ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683e78c2",
   "metadata": {},
   "source": [
    "### pytorch Avg inference time: 30-33ms\n",
    "#### more than 100% boost "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
