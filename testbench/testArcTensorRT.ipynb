{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9016ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import torchvision.transforms as transforms\n",
    "import pycuda.autoinit  # initializes CUDA driver\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38839d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "# 1. Load the engine\n",
    "with open(\"checkpoints/arcface-r100-glint360k_fp16.engine\", \"rb\") as f:\n",
    "    runtime = trt.Runtime(TRT_LOGGER)\n",
    "    engine = runtime.deserialize_cuda_engine(f.read())\n",
    "\n",
    "# 2. Create context\n",
    "context = engine.create_execution_context()\n",
    "\n",
    "# 3. Allocate buffers\n",
    "inputs, outputs, bindings, stream = [], [], [], cuda.Stream()\n",
    "\n",
    "for i in range(engine.num_io_tensors):\n",
    "    tensor_name = engine.get_tensor_name(i)\n",
    "\n",
    "    size = trt.volume(engine.get_tensor_shape(tensor_name))\n",
    "    dtype = trt.nptype(engine.get_tensor_dtype(tensor_name))\n",
    "\n",
    "    host_mem = cuda.pagelocked_empty(size, dtype)\n",
    "    device_mem = cuda.mem_alloc(host_mem.nbytes)\n",
    "\n",
    "    bindings.append(int(device_mem))\n",
    "    if engine.get_tensor_mode(tensor_name) == trt.TensorIOMode.INPUT:\n",
    "        inputs.append((host_mem, device_mem))\n",
    "    else:\n",
    "        outputs.append((host_mem, device_mem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c4538af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(input_numpy):\n",
    "    context.set_input_shape(\"input\", input_numpy.shape)\n",
    "    # Copy input data to host buffer\n",
    "    np.copyto(inputs[0][0], input_numpy.ravel())\n",
    "\n",
    "    # Transfer to GPU\n",
    "    cuda.memcpy_htod_async(inputs[0][1], inputs[0][0], stream)\n",
    "\n",
    "    # Execute\n",
    "    context.execute_v2(bindings)\n",
    "\n",
    "    # Transfer outputs back\n",
    "    cuda.memcpy_dtoh_async(outputs[0][0], outputs[0][1], stream)\n",
    "    stream.synchronize()\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaeb8318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(img):\n",
    "    # img: (C, H, W)\n",
    "    mean = np.array([0.5, 0.5, 0.5], dtype=np.float32).reshape(3, 1, 1)\n",
    "    std = np.array([0.5, 0.5, 0.5], dtype=np.float32).reshape(3, 1, 1)\n",
    "    return (img - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "818a9991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg inference time: 6.216003894805908 ms\n"
     ]
    }
   ],
   "source": [
    "def measure_inference_time(repetitions=100):\n",
    "    input_tensor = np.random.randn(repetitions, 3, 112, 112).astype(np.float32)\n",
    "\n",
    "    # warmup\n",
    "    for i in range(10):\n",
    "        _ = infer(input_tensor[0:10])\n",
    "\n",
    "    start = time.time()\n",
    "    for i in range(repetitions):\n",
    "        _ = infer(input_tensor[0:10])\n",
    "    end = time.time()\n",
    "\n",
    "    avg_time = (end - start) / repetitions\n",
    "    return avg_time\n",
    "\n",
    "print(\"Avg inference time:\", measure_inference_time() * 1000, \"ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e2a45d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.constants import QDRANT_PORT, QDRANT_HOST\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "\n",
    "collection_name = \"faces\"\n",
    "client = QdrantClient(QDRANT_HOST, grpc_port=QDRANT_PORT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf139670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(img):\n",
    "    # img: (C, H, W)\n",
    "    mean = np.array([0.5, 0.5, 0.5], dtype=np.float32).reshape(1, 1, 3)\n",
    "    std = np.array([0.5, 0.5, 0.5], dtype=np.float32).reshape(1, 1, 3)\n",
    "    return (img - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac585ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv.imread(\"amir.jpg\")\n",
    "image = normalize(image/255)\n",
    "vec = infer(image)\n",
    "vec = vec[0][0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb580176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.upsert(\n",
    "    collection_name=collection_name, \n",
    "    points=[models.PointStruct(id=1, vector=vec, payload={\"name\": \"amir\"})])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
